{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbdc740",
   "metadata": {},
   "source": [
    "### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d7410",
   "metadata": {},
   "source": [
    "Sophie Choe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739774dd",
   "metadata": {},
   "source": [
    "### Affiliation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e50823",
   "metadata": {},
   "source": [
    "Portland State University, Electrical and Computer Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1738d",
   "metadata": {},
   "source": [
    "# Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe3379",
   "metadata": {},
   "source": [
    "This is a binary classification hybrid model as proposed in \"Continuous Variable Quantum Neural Networks\", composed of 2 layers of feed forward classical layers and 4 layers of quantum neural network. Using Pennylane Tensorflow plug-in, the whole network is wrapped as a Keras sequential network, whose parameters are updated via Keras's built in loss function and optimizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d303680f",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9a114",
   "metadata": {},
   "source": [
    "keras-nightly==2.5.0.dev2021032900 PennyLane==0.17.0 StrawberryFields==0.18.0 tensorflow-2.4.0-cp38-cp38-macosx_10_9_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417078e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pennylane as qml\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fe4c9",
   "metadata": {},
   "source": [
    "The dataset used is a resampled set from credit card fraudulent trasaction dataset. The resampling was done to have genuine vs fraudulent rate to be 3:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eba7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                       Data Preparation Function\n",
    "# ===================================================================================\n",
    "\n",
    "# 1,968 samples \n",
    "data = pd.read_csv('ccfraud_10_features_1968.csv')\n",
    "\n",
    "def data_prep(data_frame):\n",
    "    \n",
    "    if len(data_frame.columns) == 12:\n",
    "        data = data_frame.iloc[:, 1:]   # weird glitch with additional column. Drop the first column\n",
    "    shuffled = data.sample(frac=1)      # shuffle data\n",
    "    features = shuffled.iloc[:, :-1]    # select only the features by dropping the last column\n",
    "    labels = shuffled.iloc[:, -1]       # select only the labels by selecting the last column\n",
    "    \n",
    "    # convert data to numpy array to use train and test split using scikitlearn\n",
    "    features_np = features.to_numpy(dtype=np.float32)\n",
    "    labels_np = labels.to_numpy(dtype=np.int32)\n",
    "    \n",
    "    # split data into train and test, features and labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_np, labels_np, test_size=0.2, random_state=42)\n",
    "        \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def one_hot(labels):  \n",
    "    \n",
    "    depth = 2\n",
    "    indices = labels.astype(np.int32)    \n",
    "    one_hot_labels = np.eye(depth)[indices].astype(np.float32) \n",
    "    \n",
    "    return one_hot_labels\n",
    "\n",
    "# one-hot encoded labels, each label of length cutoff dimension**2\n",
    "X_train, Y_train, X_test, Y_test = data_prep(data)\n",
    "y_train, y_test = one_hot(Y_train), one_hot(Y_test)\n",
    "\n",
    "# convert them into tensorflow tensors\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6da503a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Class\"]==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0074358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Class\"]==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97212fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "479592fe",
   "metadata": {},
   "source": [
    "The classical network of the model will be using two layers with 10 neurons and the output layer with 14 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c345bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                Classical Layers\n",
    "# ===================================================================================\n",
    "# Define classical layers using Keras Sequential\n",
    "\n",
    "keras.backend.set_floatx('float32')\n",
    "\n",
    "hidden = layers.Dense(10, activation =\"elu\")\n",
    "out = layers.Dense(14, activation =\"elu\")                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e9c60b",
   "metadata": {},
   "source": [
    "The output from the classical network is prepared in quantum state. The entries of output vector are used as parameters of quantum gates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de0894c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                Quantum State Encoding\n",
    "# ===================================================================================\n",
    "\n",
    "# quantum state preparation converting the classical output to quantum \n",
    "# init_layer(classical)|0> = |quantum>\n",
    "\n",
    "def init_layer(x):\n",
    "    qml.Squeezing(x[0], x[1], wires=0)\n",
    "    qml.Squeezing(x[2], x[3], wires=1)\n",
    "    qml.Beamsplitter(x[4], x[5], wires=[0,1])\n",
    "    qml.Rotation(x[6], wires=0)\n",
    "    qml.Rotation(x[7], wires=1)\n",
    "    qml.Displacement(x[8], x[9], wires=0)\n",
    "    qml.Displacement(x[10], x[11], wires=1)\n",
    "    qml.Kerr(x[12], wires=0)\n",
    "    qml.Kerr(x[13], wires=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e62ba",
   "metadata": {},
   "source": [
    "We are definiing a quantum neural network layer to iterate and initializing the gate parameters. The sequence of gates is Interferometer (consisting of a beamsplitter on both QuModes and one rotation gate per each), Squeezing gate, Interferometer, Displacement, and then Kerr gate as activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76a5d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                    Quantum Layer\n",
    "# ===================================================================================\n",
    "\n",
    "# initialize parameters for the quantum layers: number of layers x number of parameters needed for all the gates\n",
    "\n",
    "def init_weights(layers, modes, active_sd=0.0001, passive_sd=0.1):\n",
    "    \n",
    "    M = 2 + 1 + 1  # Number of interferometer parameters: beamsplitter + 2 rotations\n",
    "\n",
    "    int1_weights = tf.random.normal(shape=[layers, M], stddev=passive_sd)\n",
    "    s_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "    int2_weights = tf.random.normal(shape=[layers, M], stddev=passive_sd)\n",
    "    dr_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "    k_weights = tf.random.normal(shape=[layers, modes], stddev=active_sd)\n",
    "\n",
    "    weights = tf.concat([int1_weights, s_weights, int2_weights, dr_weights, k_weights], axis=1)\n",
    "    weights = tf.Variable(weights)\n",
    "\n",
    "    return weights\n",
    "\n",
    "# quantum layer for iteration\n",
    "\n",
    "def layer(v):\n",
    "    qml.Beamsplitter(v[0], v[1], wires=[0,1])\n",
    "    qml.Rotation(v[2], wires=0)\n",
    "    qml.Rotation(v[3], wires=1)\n",
    "    qml.Squeezing(v[4], 0.0, wires=0)\n",
    "    qml.Squeezing(v[5], 0.0, wires=1)\n",
    "    qml.Beamsplitter(v[6], v[7], wires=[0,1])\n",
    "    qml.Rotation(v[8], wires=0)\n",
    "    qml.Rotation(v[9], wires=1)\n",
    "    qml.Displacement(v[10], 0.0, wires=0)\n",
    "    qml.Displacement(v[11], 0.0, wires=1)\n",
    "    qml.Kerr(v[12], wires=0)\n",
    "    qml.Kerr(v[13], wires=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e0417a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                    Quantum Circuit\n",
    "# ===================================================================================\n",
    "\n",
    "num_modes = 2\n",
    "num_basis = 2\n",
    "\n",
    "# select a devide \n",
    "dev = qml.device(\"strawberryfields.fock\", wires=num_modes, cutoff_dim=num_basis) \n",
    "\n",
    "@qml.qnode(dev, interface=\"tf\")\n",
    "def quantum_nn(inputs, var):\n",
    "    # Encode input x into quantum state\n",
    "    init_layer(inputs)\n",
    "\n",
    "    # iterative quantum layers\n",
    "    for v in var:\n",
    "        layer(v)\n",
    "    \n",
    "    return [qml.expval(qml.X(0)), qml.expval(qml.X(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb3d72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                    Hybrid Model\n",
    "# ===================================================================================\n",
    "\n",
    "\"\"\"\n",
    "Add the quantum layer to the classical to create a hybrid model\n",
    "    1. initialize weights for quantum layers\n",
    "    2. create a dictionary of weight shape to pass as one of the variables to covert to keras layer\n",
    "    3. convert the quantum layer to a Keras layer\n",
    "    4. add to the classical sequential model\n",
    "\"\"\"\n",
    "num_layers = 4\n",
    "\n",
    "def hybrid_model(num_layers, num_modes):\n",
    "    \n",
    "    weigths = init_weights(num_layers, num_modes)\n",
    "    shape_tup = weigths.shape\n",
    "    weight_shapes = {'var': shape_tup}\n",
    "    qlayer = qml.qnn.KerasLayer(quantum_nn, weight_shapes, output_dim=4)\n",
    "    hybrid_model = tf.keras.Sequential([hidden, hidden, out, qlayer])\n",
    "    \n",
    "    return hybrid_model\n",
    "\n",
    "model = hybrid_model(num_layers, num_modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44b23d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m opt \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(opt, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSE\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m190\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Mul]"
     ]
    }
   ],
   "source": [
    "# ===================================================================================\n",
    "#                                     Training\n",
    "# ===================================================================================\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(opt, loss = 'MSE', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train,\n",
    "                    epochs = 40,\n",
    "                    batch_size = 190,\n",
    "                    shuffle = True,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd0a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                  Loss History Plot\n",
    "# ===================================================================================\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.plot(history.history['loss'], '-g', label = 'training loss')\n",
    "plt.plot(history.history['val_loss'], '-r', label = 'validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9c1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================================\n",
    "#                                Accuracy History Plot\n",
    "# ===================================================================================\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.plot(history.history['accuracy'], '-g', label = 'training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], '-r', label = 'validation loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535b0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
